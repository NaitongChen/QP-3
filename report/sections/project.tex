\section{Paper-specific project}
I noticed that most of the experiments and simulation studies in the paper only cover cases where the distributions of $f(X)$ and $g(X)\given f(X)$ are in the same family as the original data $X$ (i.e. Gaussians or Poissons with different parameters), and there is minimal discussion on when this is not the case. I would like to therefore focus my paper-specific project on an instance of data fission where $f(X)$ follows a distribution that is not in the same family as $X$ or $g(X)\given f(X)$.\\

The particular case that I would like to focus on is to \textbf{construct selective CIs in the fixed-design GLM model} where $Y_i \distiid \distGam(\alpha, \exp(\theta_i))$ where $\theta_i=\beta^\top x_i)$ (listed under Appendix B of \cite{leiner2022data}).

\begin{itemize}
\item For each $Y_i$ with $i\in\{1,\dots,n\}$, draw $Z_i=(Z_{i1}, \dots, Z_{iB})$ where each element is \iid $Z_{ib} \distas \distPoiss(Y_i)$ with $b\in\{1,\cdots,B\}$.\\
Then $f(Y_i) = Z_i$, where each element is \iid $\distNB\left(\alpha, \frac{\exp(\theta_i)}{\exp(\theta_i)+B}\right)$,\\
$g(Y_i) \given f(Y_i)$ has conditional distribution $\distGam(\alpha+\sum_{b=1}^B [f(Y_i)]_b, \exp(\theta_i) + B)$.
\newline$ $
\color{red}
I believe the marginal distribution of $f(Y_i)$ is incorrect. See \cref{eg:discrete}.
\color{black}

\item For each $Y_i$, draw $Z_i \distas \distPoiss(\tau Y_i)$ with $\tau\in(0,\infty)$.\\
Then $f(Y_i) = Z$, where each element is \iid $\distNB\left(\alpha, \frac{\theta_i}{\theta_i+\tau}\right)$,\\
$g(Y_i) \given f(Y_i)$ has conditional distribution $\distGam(\alpha+f(Y_i), \theta_i + \tau)$.
\end{itemize}

\textbf{The proposed procesure is}

\begin{itemize}
\item Decompose each $y_i$ using one of the two above procedures (assuming we are going with the second one)

\item fit $f(y_i)$ by maximizing
\[
\sum_{i=1}^n \log \distNB\left(z_i \given \alpha, \frac{\beta^\top x_i}{\beta^\top x_i+\tau}\right) + \lambda \|\beta\|_1
\]

(I've verified that this function is convex in $\beta$.)

\item Fit a Gamma GLM model using just the selected features from the previous step

\item Since $\distGam$ is in the exponential dispersion family, we can follow the exact same setup as in Appendix A.5 of \cite{leiner2022data} to use the QMLE procedure to construct CIs in the inference step.
\newline$ $
\color{red}
This function may be convex but without an argmin, or non-convex, depending on the values of $y, z$, and $\alpha$. See \cref{eg:gam_discrete,eg:gam_cont}. This is already an undesirable quality of data fission.
\color{black}

\end{itemize}

\textbf{Key areas that I would like to explore (through simulations)}
\begin{itemize}
\item compare the variables selected using decomposed data following geometric distribution against those using data splitting and the (invalid) approach of using the same dataset twice for both selection and inference. The setup that I have is mostly inline with the simulation studies in Sections 4 and 5 in \cite{leiner2022data}, however, I would like to ensure there is no influential point and all assumptions are met. This way we can better isolate the effect of transforming the original dataset to something that follows a different distribution.
\item compare the two data fission procedures laid out above with discrete and continous tuning parameters ($B$ and $\tau$) for deciding how much information is split between $f(Y)$ and $g(Y)\given f(Y)$. The second version seems like a continuous relaxation (under expectation) of the first data fission method. However, in the case with a discrete tuning parameter, the dimension of $f(Y_i)$ changes and we need to somehow account for that in the selection step. This is not addressed directly in the paper, but I think a natural way to deal with this is to think of stacking the elements of $f(Y_i)$ so that for each particular set of covariates $x_i$, we have multiple corresponding responses instead of $1$. I would like to explore the connection between these two fission processes (probably empirically) in terms of the amount of information allocated in each component of the fissioned data. The same simulation setup from the previous bullet point can be used here.
\newline $ $
\color{red} 
I believe this is no longer necessary because the result generalizing to $B>1$ does not hold?
\color{black}
\end{itemize}
\textbf{Revised plan}
\newline $ $
We investigate to what extent would we like the distributions of $X, f(X), g(X)\given f(X)$ be similar to each other, in terms of parametric family and whether the parameters are random. For all of these comparisons, pick the tuning parameter so information allocated to $f(X)$ is the same compared to the counterpart in data splitting (ideally half).
\begin{itemize}
\item compare the first two versions of data fission for Gaussian linear regression against data splitting. All three parts follow Gaussian distributions, but one version has the value of $Z$ being a parameter for the distribution of $g(X)\given f(X)$, while the other does not. This can help us study the effect of having the parameter of the distribution of $g(X)\given f(X)$ depending on $Z$. My hypothesis is that there will be higher variability on the width of the CIs.
\item compare the two versions of data fission for Possion regression against data splitting. One version has all of $X, f(X), g(X)\given f(X)$ following Possion distributions, the other version has $g(X)\given f(X)$ following a binomial distribution and the others following Possion distributions. With this we can check the effect of not having the same parametric family of distributions. Use large enough samples with we are closer to asymptotic normality. But this effect may be confounded by the fact that the Binomial version has $Z$ in the parameter while the other does not.
\item both of the previous examples check the effect on the inference step. The Gamma example on the previous page has $f(X)$ following a different distribution. We can use this to study the effect of disimilarity between $f(X)$ and $X$ on variable selection. But the corresponding MLE for the subsequent inference step is hard to optimize. If we use a working model, we can also then compare the inferential results against data splitting.
\end{itemize}